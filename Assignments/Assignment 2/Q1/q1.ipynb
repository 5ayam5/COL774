{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "K = 5\n",
    "TRAIN_DATA = \"reviews_Digital_Music_5.json/Music_Review_train.json\"\n",
    "TEST_DATA = \"reviews_Digital_Music_5.json/Music_Review_test.json\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def generate_vocabulary(file: str):\n",
    "\tvocab = defaultdict(lambda: [1 for _ in range(K)])\n",
    "\tPhi = np.zeros(K, np.float64)\n",
    "\tn = np.zeros(K, np.int32)\n",
    "\twith open(file) as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\tx = json.loads(line)\n",
    "\t\t\trating = int(x['overall']) - 1\n",
    "\t\t\tPhi[rating] += 1\n",
    "\t\t\tfor word in x['reviewText'].split():\n",
    "\t\t\t\tvocab[word][rating] += 1\n",
    "\t\t\t\tn[rating] += 1\n",
    "\tn += len(vocab)\n",
    "\treturn vocab, n, np.log(Phi / np.sum(Phi))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "log_prob = [dict() for _ in range(K)]\n",
    "def get_log_prob(vocab: defaultdict, n: list[int], pred: int, word: str):\n",
    "\tif log_prob[pred].get(word):\n",
    "\t\treturn log_prob[pred][word]\n",
    "\tif vocab.get(word) is None:\n",
    "\t\tlog_prob[pred][word] = 0\n",
    "\telse:\n",
    "\t\tlog_prob[pred][word] = np.log(vocab[word][pred] / n[pred])\n",
    "\treturn log_prob[pred][word]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def predict(vocab: defaultdict, n: np.ndarray, x: list[str], Phi: np.ndarray):\n",
    "\tpred = -1\n",
    "\tbest = -float(\"inf\")\n",
    "\tfor y, phi in enumerate(Phi):\n",
    "\t\tprob = phi\n",
    "\t\tfor word in x:\n",
    "\t\t\tprob += get_log_prob(vocab, n, y, word)\n",
    "\t\tif prob > best:\n",
    "\t\t\tbest = prob\n",
    "\t\t\tpred = y + 1\n",
    "\treturn pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def accuracy(vocab: defaultdict, n: np.ndarray, Phi: np.ndarray, file: str):\n",
    "\twith open(file) as f:\n",
    "\t\tm = 0\n",
    "\t\tcorrect = 0\n",
    "\t\tfor line in f:\n",
    "\t\t\tx = json.loads(line)\n",
    "\t\t\tpred = predict(vocab, n, x['reviewText'].split(), Phi)\n",
    "\t\t\tcorrect += pred == int(x['overall'])\n",
    "\t\t\tm += 1\n",
    "\t\treturn correct / m"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def confusion_matrix(vocab: defaultdict, n: np.ndarray, Phi: np.ndarray, file: str):\n",
    "\twith open(file) as f:\n",
    "\t\tconfusion = np.zeros((K, K), np.int32)\n",
    "\t\tfor line in f:\n",
    "\t\t\tx = json.loads(line)\n",
    "\t\t\tconfusion[int(x['overall']) - 1][predict(vocab, n, x['reviewText'].split(), Phi) - 1] += 1\n",
    "\t\treturn confusion"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "vocab, n, Phi = generate_vocabulary(TRAIN_DATA)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(accuracy(vocab, n, Phi, TRAIN_DATA))\n",
    "print(accuracy(vocab, n, Phi, TEST_DATA))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.72086\n",
      "0.6656428571428571\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(confusion_matrix(vocab, n, Phi, TRAIN_DATA))\n",
    "print(confusion_matrix(vocab, n, Phi, TEST_DATA))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  261     0    99   484  1685]\n",
      " [   18    85    54   989  1492]\n",
      " [   35     0  1193  1663  2743]\n",
      " [  107     1     2  9008  4149]\n",
      " [  135    12    29   260 25496]]\n",
      "[[   2    0    0   21  205]\n",
      " [   0    0    0   63  263]\n",
      " [   2    0    1  231  852]\n",
      " [   3    0    0  280 2825]\n",
      " [  14    0    0  202 9036]]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "c88bcd8217886c4a06b3653a3d64d637eca0a96d4c4031ee5dfe8cf426268753"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}